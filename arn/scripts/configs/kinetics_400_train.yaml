# The complete Open World Human Activity Recognition pipeline from beginning to
# end. This will probably be broken down into smaller chunks for convenience.

docstr:
  style: numpy
  from import:
    arn.data.kinetics_owl:
      - KineticsOWL
      - KineticsOWLExperiment
    arn.models.fine_tune:
      - FineTune
      - FineTuneFC
    arn.models.novelty_detector:
      - WindowedMeanKLDiv
    arn.models.owhar:
      - OWHAPredictor
  #import:
  #  - torch
  main: run #KineticsOWL.run

KineticsOWL: # Pipeline for the Open World Learning Data process
  seed: 0
  environment:
    KineticsOWLExperiment:
      shared_dataloader_kwargs:
        annotation_path: $HOME/workspace/research/osr/repos/har/data/analysis/kinetics/kinetics_400_600_700_2020.csv
        kinetics_class_map: # TODO add location of file.
        sample_dirs:
          kinetics400_dir: x3d-features-k400/
          kinetics600_dir: x3d-features-k600/
          kinetics700_2020_dir: x3d-features-k700_2020/
          # Support Environment Variables in config.
          root_dir: $HOME/workspace/research/osr/repos/har/data
      start:
        KineticsUnifiedFeatures:
          subset:
            KineticsSplitConfig:
              kinetics400:
                KineticsSplitConfig:
                  train: True
                  validate: True
                  test: True
    label_id: 'kinetics700_map' # TODO check if any k400 are cut. or other changes.
  predictor:
    OWHAPredictor: # the Open World Agent
      fine_tuning:
        FineTune:
          model:
            FineTuneFC:
              input_size: 512
              depth: 5
              width: 512
              #activation: torch.nn.LeakyReLU
              dropout: 0.5
          batch_size: 1000
          epochs: 25
      novelty_detector: # Classification + Clustering
        WindowedMeanKLDiv:
          detection_threshold:
          kl_threshold:
          kl_threshold_decay_rate:
          mean_train:
          std_dev_train:
          window_size:
          num_rounds:
      # TODO checkpoints for saving the model results.
  #measures:
  #  per_step:
  #    - acc
  #    - top-5 acc
  #    - loss
  #    - mcc
  #    - nmi
  #    #- novelty_detection: # TODO
  #    #  ConfusionMatrix:
  #  cummulative:
  #    - novelty_detection # TODO
  #    - acc
  #    - top-5 acc
  #    - loss
  #    - mcc
  #    - nmi
